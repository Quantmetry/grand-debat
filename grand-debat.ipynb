{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/quantmetry.png\" width=400>\n",
    "<center><h1>TALAGRAND</h1></center>\n",
    "<center><h2>Traitement Automatique du LAngage au service du GRANd Débat National</h2></center>\n",
    "\n",
    "\n",
    "Ce notebook met à disposition des citoyens des outils d'Intelligence Artificielle pour appréhender le nombre important de contributions au Grand Débat.\n",
    "\n",
    "Mots clés : **NLP, TAL, LDA, Embeddings, TextRank**\n",
    "\n",
    "Pour plus d'informations, se référer à cet [article](quantmetry.com/grand-debat).\n",
    "\n",
    "Auteurs : [Antoine SIMOULIN](asimoulin@quantmetry.com), [Antoine ISNARDY](aisnardy@quantmetry.com), [Thibaud REAL DEL SARTE](trealdelsarte@quantmetry.com)\n",
    "\n",
    "**DISCLAIMER** : Quantmetry et les auteurs de ce notebook ne peuvent être tenus responsables de l'interprétation des réponses aux questions posées lors du Grand Débat. Le présent notebook fournit une grille d'analyse desdites réponses, non une interprétation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Téléchargement des données\n",
    "-  Récupérer la liste des thèmes en analysant le site du Grand Débat\n",
    "-  Sélectionner un thème en modifiant la variable `selected_theme`\n",
    "-  Télécharger ensuite le fichier json le plus récent associé à un thème depuis datagouv.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.downloading import download_data, get_themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = get_themes()\n",
    "list(themes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir le numéro associé au thème que l'on souhaite étudier\n",
    "selected_theme = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data(themes, selected_theme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "-  Charger le fichier json précédemment téléchargé\n",
    "-  Afficher les différentes questions associées au thème sélectionné\n",
    "-  Sélectionner une question à étudier (variable `selected_question`)\n",
    "-  Afficher le nombre de réponses existantes correspondant à cette question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.loading import load_data, load_question, get_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_path(themes, selected_theme)\n",
    "data_theme_json = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_theme_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_id = [r['questionId'] for x in data_theme_json for r in x['responses']]\n",
    "questions_id = list(set(questions_id))\n",
    "questions_title = [r['questionTitle'] for x in data_theme_json for r in x['responses']]\n",
    "questions_title = list(set(questions_title))\n",
    "for id, title in zip(questions_id, questions_title):\n",
    "    print(\"ID : {} - Question: {}\".format(id, title))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer ici l'identifiant associé à la question étudiée\n",
    "selected_question = 'UXVlc3Rpb246MTU5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_question = str(selected_question)\n",
    "data_theme_response_dict = load_question(questions_id, data_theme_json, selected_question)\n",
    "print(\"Nombre de réponses analysées :\", len(data_theme_response_dict[selected_question]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2>Détection de thèmes</h2>\n",
    "-  Détecter les thèmes principaux associés à la question sélectionnée en utilisant l'algorithme **LDA** (Latent Dirichlet Allocation)\n",
    "-  Le resultat de l'analyse se trouve dans le fichier pyLDAVIS_tf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.theme_detection import get_themes\n",
    "tf_vectorizer, lda_tf = get_themes(data_theme_response_dict, selected_question)\n",
    "print(\"Les différents thèmes associés à la question se situent dans le fichier pyLDAVIS_tf.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2>Résumé de chaque thème</h2>\n",
    "-  Résumer un grand thème en utilisant TextRank, technique de résumé extractive\n",
    "-  Spécifier le nombre de phrases que l'on souhaite pour former le résumé dans la variable `sn`\n",
    "-  Les résultats se situent dans le fichier demo.docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.text_summarization import prepare_data, apply_page_rank_algorithm, create_titles\n",
    "from grand_debat.vectorization import sentence_to_vec\n",
    "from grand_debat.clusterisation import apply_clusterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer le document texte en un ensemble de phrases dont la typographie est standardisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentences = prepare_data(data_theme_response_dict, selected_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupérer la phrase la plus caractéristique de chaque thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_mixture_topics, title_sentences, titles = create_titles(clean_sentences, tf_vectorizer, lda_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associer à chaque phrase du corpus son thème (issu de **LDA**) le plus carctéristique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_paragraph = apply_clusterisation(sentences_mixture_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Représenter chaque phrase sous la forme d'un vecteur dense. Ces vecteurs sont obtenus à partir d'embeddings entraînés à partir de l'ensemble des contributions au Grand Débat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectors, word_embeddings = sentence_to_vec(clean_sentences, file_model='word2vec.38k.150d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique alors l'algorithme **TextRank** à l'ensemble des phrases d'un thème pour en extraire les phrases carctéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indiquer le nombre de phrases qui formeront le résumé\n",
    "sn = 10\n",
    "apply_page_rank_algorithm(clean_sentences, sentences_paragraph, word_embeddings, sn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export de la synthèse sous la forme d'un document word\n",
    "-  Créer le document final contenant les résumés pour chaque thème de la question.\n",
    "-  Le processus prend environ 20 minutes sur une machine équipée d'un intel core i5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grand_debat.saving import create_final_doc, get_theme, get_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_sentence = get_theme(themes, selected_theme)\n",
    "question_sentence = get_question(questions_id, questions_title, selected_question)\n",
    "create_final_doc(title_sentences, titles, clean_sentences,\n",
    "                 sentences_paragraph, word_embeddings, theme_sentence, question_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
